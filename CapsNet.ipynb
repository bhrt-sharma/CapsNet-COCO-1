{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from keras import layers, models, optimizers\n",
    "from keras import callbacks\n",
    "from PIL import Image\n",
    "\n",
    "from utils import combine_images\n",
    "from capsule_layers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, n_class, routings):\n",
    "    \"\"\"\n",
    "    A Capsule Network on MSCOCO 2017 dataset.\n",
    "    :param input_shape: data shape, 3d, [width, height, channels]\n",
    "    :param n_class: number of classes\n",
    "    :param routings: number of routing iterations\n",
    "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
    "            `eval_model` can also be used for training.\n",
    "    \"\"\"\n",
    "    x = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Layer 1: Just a conventional Conv2D layer\n",
    "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "    # Layer 4: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primary_caps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "    # Layer 5: Capsule layer. Routing algorithm works here.\n",
    "    caption_caps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='caption_caps')(primary_caps)\n",
    "\n",
    "    # Layer 6: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "    # If using tensorflow, this will not be necessary. :)\n",
    "    out_caps = Length(name='capsnet')(caption_caps)\n",
    "\n",
    "    # Decoder network.\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([caption_caps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(caption_caps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
    "    decoder.add(layers.Dense(1024, activation='relu'))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    # Models for training and evaluation (prediction)\n",
    "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "    # manipulate model\n",
    "    noise = layers.Input(shape=(n_class, 16))\n",
    "    noised_caption_caps = layers.Add()([caption_caps, noise])\n",
    "    masked_noised_y = Mask()([noised_caption_caps, y])\n",
    "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "    return train_model, eval_model, manipulate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, args):\n",
    "    \"\"\"\n",
    "    Training a CapsuleNet\n",
    "    :param model: the CapsuleNet model\n",
    "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
    "    :param args: arguments\n",
    "    :return: The trained model\n",
    "    \"\"\"\n",
    "    # unpacking the data\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "\n",
    "    # callbacks\n",
    "    log = callbacks.CSVLogger(args['save_dir'] + '/log.csv')\n",
    "    tb = callbacks.TensorBoard(log_dir=args['save_dir'] + '/tensorboard-logs',\n",
    "                               batch_size=args['batch_size'], histogram_freq=int(args['debug']))\n",
    "    checkpoint = callbacks.ModelCheckpoint(args['save_dir'] + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\n",
    "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
    "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args['lr'] * (args['lr_decay'] ** epoch))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(lr=args['lr']),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., args['lam_recon']],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "    # Begin: Training ----------------------------------------------------------------------------------------#\n",
    "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args['batch_size'], epochs=args['epochs'],\n",
    "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
    "    # End: Training ------------------------------------------------------------------------------------------#\n",
    "\n",
    "    model.save_weights(args['save_dir'] + '/trained_model.h5')\n",
    "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args['save_dir'])\n",
    "\n",
    "    from utils import plot_log\n",
    "    plot_log(args['save_dir'] + '/log.csv', show=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, args):\n",
    "    x_test, y_test = data\n",
    "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
    "    print('-'*30 + 'Begin: test' + '-'*30)\n",
    "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
    "\n",
    "    img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n",
    "    image = img * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
    "    print()\n",
    "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
    "    print('-' * 30 + 'End: test' + '-' * 30)\n",
    "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco():\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    \n",
    "    # Load dataset from disk\n",
    "    x_train = pickle.load(open('dataset/x_train.pickle', 'rb'))\n",
    "    x_train = np.expand_dims(x_train, axis=-1).astype('float32') / 255.\n",
    "\n",
    "    y_train = pickle.load(open('dataset/y_train.pickle', 'rb'))\n",
    "\n",
    "    x_test = pickle.load(open('dataset/x_val.pickle', 'rb'))\n",
    "    x_test = np.expand_dims(x_test, axis=-1).astype('float32') / 255.\n",
    "    \n",
    "    y_test = pickle.load(open('dataset/y_val.pickle', 'rb'))\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = load_coco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 60, 60, 96)   16320       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 28, 28, 96)   230496      conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 20, 20, 256)  1990912     conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 6, 6, 256)    5308672     conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1152, 8)      0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1152, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "caption_caps (CapsuleLayer)     (None, 12, 16)       1769472     primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_7 (Mask)                   (None, 192)          0           caption_caps[0][0]               \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 12)           0           caption_caps[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 250, 250, 1)  64686628    mask_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 74,002,500\n",
      "Trainable params: 74,002,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define and display model\n",
    "# model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:], n_class=12, routings=3)\n",
    "model, eval_model, manipulate_model = CapsNet(input_shape=(250, 250, 1), n_class=12, routings=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['epochs'] = 50\n",
    "args['batch_size'] = 100\n",
    "args['lr'] = 0.001\n",
    "args['lr_decay'] = 0.9\n",
    "args['lam_recon'] = 0.392\n",
    "args['routings'] = 3\n",
    "args['shift_fraction'] = 0.1\n",
    "args['debug'] = False\n",
    "args['save_dir'] = './result'\n",
    "args['testing'] = False\n",
    "args['super'] = 5\n",
    "args['weights'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=model, data=((x_train, y_train), (x_test, y_test)), args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
