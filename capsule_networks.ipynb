{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supercategory to ID map table:\n",
    "\n",
    "| ID | Supercategory |\n",
    "|----|---------------|\n",
    "| 0  |  furniture |\n",
    "| 1  |  animal |\n",
    "| 2  |  electronic |\n",
    "| 3  |  outdoor |\n",
    "| 4  |  person |\n",
    "| 5  |  sports |\n",
    "| 6  |  food |\n",
    "| 7  |  vehicle |\n",
    "| 8  |  kitchen |\n",
    "| 9  |  accessory |\n",
    "| 10 |  appliance |\n",
    "| 11 |  indoor |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from disk\n",
    "pickle_in_x = open('X_train.pickle', 'rb')\n",
    "X_train = pickle.load(pickle_in_x)\n",
    "\n",
    "pickle_in_y = open('y_train.pickle', 'rb')\n",
    "y_train = pickle.load(pickle_in_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4925, 50, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of the feature vector\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4925, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of the label vector\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of CapsNet\n",
    "\n",
    "```\n",
    "                            Loss\n",
    "                              ↑\n",
    "                    ┌─────────┴─────────┐\n",
    "      Labels → Margin Loss      Reconstruction Loss\n",
    "                    ↑                   ↑\n",
    "                  Length             Decoder\n",
    "                    ↑                   ↑ \n",
    "          Supercategory Capsules ──Mask─┘\n",
    "               ↖↑↗ ↖↑↗ ↖↑↗\n",
    "             Primary Capsules\n",
    "                    ↑      \n",
    "               Input Images\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Images\n",
    "\n",
    "Input images are of size (img_size x img_size) pixels and are grayscale thus channel=1. We don't know the batch size thus the first dimension of the shape is None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, img_size, img_size, 1], dtype=tf.float32, name='X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primary Capsules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the output of primary capsules, we apply two regular convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_n_maps = 32\n",
    "caps1_n_dims = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_params = {\n",
    "    'filters': 256,\n",
    "    'kernel_size': 5,\n",
    "    'strides': 2,\n",
    "    'padding': 'valid',\n",
    "    'activation': tf.nn.relu\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    'filters': caps1_n_maps * caps1_n_dims,  # 256 convolutional filters\n",
    "    'kernel_size': 3,\n",
    "    'strides': 4,\n",
    "    'padding': 'valid',\n",
    "    'activation': tf.nn.relu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X, name='conv1', **conv1_params)\n",
    "conv2 = tf.layers.conv2d(conv1, name='conv2', **conv2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv1/Relu:0\", shape=(?, 23, 23, 256), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(?, 6, 6, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions of the convolutional layers\n",
    "print(conv1)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1152 primary capsules.\n"
     ]
    }
   ],
   "source": [
    "caps1_dim = int(conv2.shape[1])\n",
    "caps1_n_caps = caps1_n_maps * caps1_dim * caps1_dim\n",
    "print('We have %d primary capsules.' % caps1_n_caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer contains 32 maps of *(caps1_dim x caps1_dim)* capsules each, and each capsule will output a 8D activation vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we reshape the output to get a bunch of 8D vectors representing output of primary capsules. We chop the 256 of conv2 into 32 vectors of 8 dimensions each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_raw:0' shape=(?, 1152, 8) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims], name='caps1_raw')\n",
    "caps1_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the vectors need to be squashed.\n",
    "We cannot directly use the tf.norm() function because the derivative of || s || is undefined for || s || = 0. So we compute the square root by adding epislon value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name='squash'):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keepdims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"caps1_output/mul:0\", shape=(?, 1152, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "caps1_output = squash(caps1_raw, name='caps1_output')\n",
    "print(caps1_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "caps1_output is the output of the first capsule layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supercategory Capsules\n",
    "\n",
    "To compute the output of the supercategory capsules, we must first compute the predicted output vectors (one for each primary / supercategory capsule pair). Then we can run the routing by agreement algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Predicted Output Vectors\n",
    "\n",
    "The supercategory capsule layer contains 12 capsules (one for each supercategory) of 16 dimensions each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_n_caps = 12\n",
    "caps2_n_dims = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each capsule $i$ in the first layer, we want to predict the output of every capsule $j$ in the second layer. For this, we will need a transformation matrix $\\mathbf{W}_{i,j}$ (one for each pair of capsules ($i$, $j$)), then we can compute the predicted output $\\hat{\\mathbf{u}}_{j|i} = \\mathbf{W}_{i,j} \\, \\mathbf{u}_i$. Since we want to transform an 8D vector into a 16D vector, each transformation matrix $\\mathbf{W}_{i,j}$ must have a shape of (16, 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute $\\hat{\\mathbf{u}}_{j|i}$ for every pair of capsules ($i$, $j$), a feature of `tf.matmul()` function will be used. In addition to matrix multiplication, `tf.matmul()` also allows multiplication of higher dimensional arrays. It treats the higher dimensional arrays as arrays of matrices, and it performs itemwise matrix multiplication. For example, suppose there are two 4D arrays, each containing a 2×3 grid of matrices. The first contains matrices $\\mathbf{A}, \\mathbf{B}, \\mathbf{C}, \\mathbf{D}, \\mathbf{E}, \\mathbf{F}$ and the second contains matrices $\\mathbf{G}, \\mathbf{H}, \\mathbf{I}, \\mathbf{J}, \\mathbf{K}, \\mathbf{L}$. On multiplying these two 4D arrays using the `tf.matmul()` function, we get:\n",
    "\n",
    "$\n",
    "\\pmatrix{\n",
    "\\mathbf{A} & \\mathbf{B} & \\mathbf{C} \\\\\n",
    "\\mathbf{D} & \\mathbf{E} & \\mathbf{F}\n",
    "} \\times\n",
    "\\pmatrix{\n",
    "\\mathbf{G} & \\mathbf{H} & \\mathbf{I} \\\\\n",
    "\\mathbf{J} & \\mathbf{K} & \\mathbf{L}\n",
    "} = \\pmatrix{\n",
    "\\mathbf{AG} & \\mathbf{BH} & \\mathbf{CI} \\\\\n",
    "\\mathbf{DJ} & \\mathbf{EK} & \\mathbf{FL}\n",
    "}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply this function to compute $\\hat{\\mathbf{u}}_{j|i}$ for every pair of capsules ($i$, $j$) like this (recall that there are 42×42×32=56448 capsules in the first layer, and 12 in the second layer):\n",
    "\n",
    "$\n",
    "\\pmatrix{\n",
    "  \\mathbf{W}_{1,1} & \\mathbf{W}_{1,2} & \\cdots & \\mathbf{W}_{1,10} \\\\\n",
    "  \\mathbf{W}_{2,1} & \\mathbf{W}_{2,2} & \\cdots & \\mathbf{W}_{2,10} \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\mathbf{W}_{1152,1} & \\mathbf{W}_{1152,2} & \\cdots & \\mathbf{W}_{1152,10}\n",
    "} \\times\n",
    "\\pmatrix{\n",
    "  \\mathbf{u}_1 & \\mathbf{u}_1 & \\cdots & \\mathbf{u}_1 \\\\\n",
    "  \\mathbf{u}_2 & \\mathbf{u}_2 & \\cdots & \\mathbf{u}_2 \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\mathbf{u}_{1152} & \\mathbf{u}_{1152} & \\cdots & \\mathbf{u}_{1152}\n",
    "}\n",
    "=\n",
    "\\pmatrix{\n",
    "\\hat{\\mathbf{u}}_{1|1} & \\hat{\\mathbf{u}}_{2|1} & \\cdots & \\hat{\\mathbf{u}}_{10|1} \\\\\n",
    "\\hat{\\mathbf{u}}_{1|2} & \\hat{\\mathbf{u}}_{2|2} & \\cdots & \\hat{\\mathbf{u}}_{10|2} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\hat{\\mathbf{u}}_{1|1152} & \\hat{\\mathbf{u}}_{2|1152} & \\cdots & \\hat{\\mathbf{u}}_{10|1152}\n",
    "}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the first array is (56448, 12, 16, 8), and the shape of the second array is (56448, 12, 8, 1). Note that the second array must contain 12 identical copies of the vectors $\\mathbf{u}_1$ to $\\mathbf{u}_{56448}$. To create this array, we will use the handy `tf.tile()` function, which lets you create an array containing many copies of a base array, tiled in any way you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we also need to consider the _batch size_. Say we feed 50 images to the capsule network, it will make predictions for these 50 images simultaneously. So the shape of the first array must be (50, 56448, 12, 16, 8), and the shape of the second array must be (50, 56448, 12, 8, 1). The first layer capsules actually already output predictions for all 50 images, so the second array will be fine, but for the first array, we will need to use `tf.tile()` to have 50 copies of the transformation matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we start by creating a trainable variable of shape (1, 56448, 12, 16, 8) that will hold all the transformation matrices. The first dimension of size 1 will make this array easy to tile. The transformation matrix needs to be initialized with random values, so we initialize this variable randomly using a normal distribution with a standard deviation to 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the transformation matrix variable W\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name='W_init'\n",
    ")\n",
    "W = tf.Variable(W_init, name='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the first array by repeating W per instance\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name='W_tiled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now moving on to the second array. We need to create an array of shape (_batch size_, 56448, 12, 8, 1), containing the output of the first layer capsules, repeated 12 times (once per supercategory, along the third dimension, which is axis=2). The `caps1_output` array has a shape of (_batch size_, 56448, 8), so we first need to expand it twice, to get an array of shape (_batch size_, 56448, 1, 8, 1), then we can repeat it 12 times along the third dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1, name='caps1_output_expanded')\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2, name='caps1_output_tile')\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1], name='caps1_output_tiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"W_tiled:0\", shape=(?, 1152, 12, 16, 8), dtype=float32)\n",
      "Tensor(\"caps1_output_tiled:0\", shape=(?, 1152, 12, 8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Now check the shapes\n",
    "print(W_tiled)\n",
    "print(caps1_output_tiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to get all the predicted output vectors $\\hat{\\mathbf{u}}_{j|i}$, we multiply the two arrays using `tf.matmul()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled, name='caps2_predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_predicted:0' shape=(?, 1152, 12, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape\n",
    "caps2_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each instance in the batch and for each pair of first and second layer capsules (56448×12) we have a 16D predicted output column vector (16×1). Now we can apply the apply the routing by agreement algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing by agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, initialize the raw routing weights $b_{i,j}$ to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1], dtype=np.float32, name='raw_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for adding two extra dimensions to raw_weights is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, apply the softmax function to compute the routing weights, $\\mathbf{c}_{i} = \\operatorname{softmax}(\\mathbf{b}_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_weights = tf.nn.softmax(raw_weights, axis=2, name='routing_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the weighted sum of all the predicted output vectors for each second-layer capsule, $\\mathbf{s}_j = \\sum\\limits_{i}{c_{i,j}\\hat{\\mathbf{u}}_{j|i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted, name='weighted_predictions')\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keepdims=True, name='weighted_sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To perform elementwise matrix multiplication, we use the `tf.multiply()` function. It requires `routing_weights` and `caps2_predicted` to have the same rank, which is why two extra dimensions of size 1 were added to `routing_weights`, earlier.\n",
    "* The shape of `routing_weights` is (_batch size_, 56448, 12, 1, 1) while the shape of `caps2_predicted` is (_batch size_, 56448, 12, 16, 1).  Since they don't match on the fourth dimension (1 _vs_ 16), `tf.multiply()` automatically _broadcasts_ the `routing_weights` 16 times along that dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's apply the squash function to get the outputs of the second layer capsules at the end of the first iteration of the routing by agreement algorithm, $\\mathbf{v}_j = \\operatorname{squash}(\\mathbf{s}_j)$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_round_1 = squash(weighted_sum, axis=-2, name='caps2_output_round_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 12, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_round_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ten 16D output vectors for each instance, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's measure how close each predicted vector $\\hat{\\mathbf{u}}_{j|i}$ is to the actual output vector $\\mathbf{v}_j$ by computing their scalar product $\\hat{\\mathbf{u}}_{j|i} \\cdot \\mathbf{v}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Quick math reminder: if $\\vec{a}$ and $\\vec{b}$ are two vectors of equal length, and $\\mathbf{a}$ and $\\mathbf{b}$ are their corresponding column vectors (i.e., matrices with a single column), then $\\mathbf{a}^T \\mathbf{b}$ (i.e., the matrix multiplication of the transpose of $\\mathbf{a}$, and $\\mathbf{b}$) is a 1×1 matrix containing the scalar product of the two vectors $\\vec{a}\\cdot\\vec{b}$. In Machine Learning, we generally represent vectors as column vectors, so when we talk about computing the scalar product $\\hat{\\mathbf{u}}_{j|i} \\cdot \\mathbf{v}_j$, this actually means computing ${\\hat{\\mathbf{u}}_{j|i}}^T \\mathbf{v}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need to compute the scalar product $\\hat{\\mathbf{u}}_{j|i} \\cdot \\mathbf{v}_j$ for each instance, and for each pair of first and second level capsules $(i, j)$, we will once again use `tf.matmul()` to multiply many matrices simultaneously. This will require playing around with `tf.tile()` to get all dimensions to match (except for the last 2). So let's look at the shape of `caps2_predicted`, which holds all the predicted output vectors $\\hat{\\mathbf{u}}_{j|i}$ for each instance and each pair of capsules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_predicted:0' shape=(?, 1152, 12, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's look at the shape of `caps2_output_round_1`, which holds 12 outputs vectors of 16D each, for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 12, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_round_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get these shapes to match, we just need to tile the `caps2_output_round_1` array 56448 times (once per primary capsule) along the second dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1], name='caps2_output_round_1_tiled'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled, transpose_a=True, name='agreement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now update the raw routing weights $b_{i,j}$ by simply adding the scalar product $\\hat{\\mathbf{u}}_{j|i} \\cdot \\mathbf{v}_j$ we just computed: $b_{i,j} \\gets b_{i,j} + \\hat{\\mathbf{u}}_{j|i} \\cdot \\mathbf{v}_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weights_round_2 = tf.add(raw_weights, agreement, name='raw_weights_round_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of round 2 is the same as in round 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_weights_round_2 = tf.nn.softmax(\n",
    "    raw_weights_round_2, axis=2, name='routing_weights_round_2'\n",
    ")\n",
    "\n",
    "weighted_predictions_round_2 = tf.multiply(\n",
    "    routing_weights_round_2, caps2_predicted, name='weighted_predictions_round_2'\n",
    ")\n",
    "\n",
    "weighted_sum_round_2 = tf.reduce_sum(\n",
    "    weighted_predictions_round_2, axis=1, keepdims=True, name='weighted_sum_round_2'\n",
    ")\n",
    "\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2, axis=-2, name='caps2_output_round_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want, we can go for a few more rounds, by repeating exactly the same steps as in round 2. But for now, we stop here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output = caps2_output_round_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 12, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimated Class Probabilities (Length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lengths of the output vectors represent class probabilities. We cannot use the `tf.norm()` function directly because of the risk discussed during writing squash function. So we create our own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_norm(s, axis=-1, epsilon=1e-7, keepdims=False, name=None):\n",
    "    with tf.name_scope(name, default_name='safe_norm'):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keepdims=keepdims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"y_proba/Sqrt:0\", shape=(?, 1, 12, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "print(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unnecessary dimensions\n",
    "y_pred = tf.cast(tf.squeeze(y_proba, axis=[1, -1]), tf.int64, name='y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_pred:0' shape=(?, 12) dtype=int64>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the multi-hot vector\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to define the training operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a placeholder for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(shape=[None, caps2_n_caps], dtype=tf.int64, name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Margin loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margin loss formula to make it possible to detect two or more digits in an image.\n",
    "\n",
    "$ L_k = T_k \\max(0, m^{+} - \\|\\mathbf{v}_k\\|)^2 + \\lambda (1 - T_k) \\max(0, \\|\\mathbf{v}_k\\| - m^{-})^2$\n",
    "\n",
    "* $T_k$ is equal to 1 if the digit of class $k$ is present, or 0 otherwise.\n",
    "* $m^{+} = 0.9$, $m^{-} = 0.1$ and $\\lambda = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `y` will contain the supercategory classes, from 0 to 12, to get $T_k$ for every instance and every class, we just use the `tf.one_hot()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'T:0' shape=(?, 12, 12) dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute the norm of the output vector for each output capsule and each instance. First, let's verify the shape of `caps2_output`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 12, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 16D output vectors are in the second to last dimension of `caps2_output`, so we use `safe_norm()` with `axis=-2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_norm/Sqrt:0' shape=(?, 1, 12, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keepdims=True, name='caps2_output_norm')\n",
    "caps2_output_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute $\\max(0, m^{+} - \\|\\mathbf{v}_k\\|)^2$, and reshape the result to get a simple matrix of shape (_batch size_, 12):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'present_error:0' shape=(?, 12) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm), name='present_error_raw')\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, caps2_n_caps), name='present_error')\n",
    "present_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's compute $\\max(0, \\|\\mathbf{v}_k\\| - m^{-})^2$ and reshape it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'absent_error:0' shape=(?, 12) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus), name='absent_error_raw')\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, caps2_n_caps), name='absent_error')\n",
    "absent_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation below requires `y` to be of the type `float32`, so we cast `y` into the required data type first and then compute the loss for each instance and each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error, name='L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sum the supercategory losses for each instance ($L_0 + L_1 + \\cdots + L_{11}$), and compute the mean over all instances. This gives us the final margin loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'margin_loss:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name='margin_loss')\n",
    "margin_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a decoder network needs to be added on top of the capsule network. It is a regular 3-layer fully connected neural network which will learn to reconstruct the input images based on the output of the capsule network. This will force the capsule network to preserve all the information required to reconstruct the image, across the whole network. This constraint regularizes the model: it reduces the risk of overfitting the training set, and it helps to generalize supercategories on new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, instead of sending all the outputs of the capsule network to the decoder network, we send only the output vector that corresponds to the target supercategory. All the other output vectors must be masked out. At inference time, we must mask all output vectors except for the longest one, i.e., the one that corresponds to the predicted supercategory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a placeholder to tell TensorFlow whether we want to mask the output vectors based on the labels (`True`) or on the predictions (`False`, the default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_with_lables (tf.placeholder_with_default), will return False when its output will not be fed\n",
    "# shape=() means a scalar value\n",
    "mask_with_labels = tf.placeholder_with_default(False, shape=(), name='mask_with_lables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use `tf.cond()` to define the reconstruction targets as the label `y` is `mask_with_lables` is `True`, or `y_pred` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_targets = tf.cond(\n",
    "    mask_with_labels,  # condition\n",
    "    lambda: y,  # true function (if True)\n",
    "    lambda: y_pred,  # false function (if False)\n",
    "    name='reconstruction_targets'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.cond()` function expects the if-True and if-False tensors to be passed _via_ functions: these functions will be called just once during the graph construction phase (not during the execution phase), similar to `tf.while_loop()`. This allows TensorFlow to add the necessary operations to handle the conditional evaluation of the if-True or if-False tensors.  \n",
    "However, in our case, the tensors `y` and `y_pred` are already created by the time we call `tf.cond()`, so unfortunately TensorFlow will consider both `y` and `y_pred` to be dependencies of the `reconstruction_targets` tensor. The `reconstruction_targets` tensor will end up with the correct value, but:\n",
    "1. whenever we evaluate a tensor that depends on `reconstruction_targets`, the `y_pred` tensor will be evaluated (even if `mask_with_layers` is `True`). This is not a big deal because computing `y_pred` adds no computing overhead during training, since we need it anyway to compute the margin loss. And during testing, if we are doing classification, we won't need reconstructions, so `reconstruction_targets` won't be evaluated at all.\n",
    "2. we will always need to feed a value for the `y` placeholder (even if `mask_with_layers` is `False`). This is a bit annoying, but we can pass an empty array, because TensorFlow won't use it anyway (it just does not know it yet when it checks for dependencies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reconstruction_targets, we need to create the reconstruction_mask. It should be equal to 1.0 for the target class, and 0.0 for the other classes, for each instance. For this we can just use the `tf.one_hot()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_mask = tf.one_hot(reconstruction_targets, depth=caps2_n_caps, name='reconstruction_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reconstruction_mask:0' shape=(?, 12, 12) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of reconstruction_mask\n",
    "reconstruction_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 12, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the shape of reconstruction_mask with caps2_output\n",
    "caps2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To multiply `reconstruction_mask` to `caps2_output`, we need to reshape `reconstruction_mask` to (_batch size_, 1, 12, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_mask_reshaped = tf.reshape(reconstruction_mask, [-1, caps2_n_caps, caps2_n_caps, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can apply the mask\n",
    "caps2_output_masked = tf.multiply(caps2_output, reconstruction_mask_reshaped, name='caps2_output_masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_masked:0' shape=(?, 12, 12, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the decoder's inputs\n",
    "# This will give an array of shape (batch_size, 192)\n",
    "decoder_input = tf.reshape(caps2_output_masked, [-1, caps2_n_caps * caps2_n_dims], name='decoder_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_input:0' shape=(?, 192) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder will contain, two dense (fully connected) ReLU layers followed by a dense output sigmoid layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = img_size * img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('decoder'):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1, activation=tf.nn.relu, name='hidden1')\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name='hidden2')\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output, activation=tf.nn.sigmoid, name='decoder_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction loss is the squared difference between the input image and the reconstructed image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = tf.reshape(X, [-1, n_output], name='X_flat')\n",
    "squared_difference = tf.square(X_flat - decoder_output, name='squared_difference')\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference, name='reconstruction_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final loss is the sum of the margin loss and the reconstruction loss (scaled down by a factor of 0.0005 to ensure the margin loss dominates training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'loss:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.0005\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name='loss')\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Touches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the model's accuracy, we need to count the number of instances that are properly classified. For this, we can simply compare `y` and `y_pred`, convert the boolean value to a float32 (0.0 for False and 1.0 for True), and compute the mean over all instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.equal(y, y_pred, name='correct')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Adam Optimizer with default parameter values\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name='training_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init and Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction of the network is done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of this capsule network will be done in a pretty standard way i.e. there won't be any fancy hyperparameter tuning, dropout or anything, we will just run the training operation over and over again, displaying the loss, and at the end of each epoch, measure the accuracy on the validation set, display it, and save the model if the validation loss is the lowest seen found so far (this is a basic way to implement early stopping, without actually stopping). Here are a few details to note:\n",
    "* if a checkpoint file exists, it will be restored (this makes it possible to interrupt training, then restart it later from the last checkpoint),\n",
    "* we must not forget to feed `mask_with_labels=True` during training,\n",
    "* during testing, we let `mask_with_labels` default to `False` (but we still feed the labels since they are required to compute the accuracy),\n",
    "* the images loaded _via_ `mnist.train.next_batch()` are represented as `float32` arrays of shape \\[784\\], but the input placeholder `X` expects a `float32` array of shape \\[28, 28, 1\\], so we must reshape the images before we feed them to our model,\n",
    "* we evaluate the model's loss and accuracy on the full validation set (5,000 instances). To view progress and support systems that don't have a lot of RAM, the code evaluates the loss and accuracy on one batch at a time, and computes the mean loss and mean accuracy at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50, 50)\n",
      "(2, 12)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [2,12,12] vs. [2,12]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](T, present_error)]]\n\t [[Node: loss/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1125_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'mul', defined at:\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-9cd0d87a5ea3>\", line 1, in <module>\n    L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error, name='L')\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 971, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1198, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4689, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [2,12,12] vs. [2,12]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](T, present_error)]]\n\t [[Node: loss/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1125_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,12,12] vs. [2,12]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](T, present_error)]]\n\t [[Node: loss/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1125_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-f86724b4c11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mmask_with_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 }\n\u001b[1;32m     36\u001b[0m             )\n",
      "\u001b[0;32m~/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,12,12] vs. [2,12]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](T, present_error)]]\n\t [[Node: loss/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1125_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'mul', defined at:\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-9cd0d87a5ea3>\", line 1, in <module>\n    L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error, name='L')\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 971, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1198, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4689, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/shan/Packages/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [2,12,12] vs. [2,12]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](T, present_error)]]\n\t [[Node: loss/_61 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1125_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 10\n",
    "restore_checkpoint = True\n",
    "\n",
    "n_iterations_per_epoch = X_train.shape[0] // batch_size\n",
    "# n_iterations_validation = X_train.shape[0] // (batch_size * 2)\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = '.'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        counter = 0\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            if counter + batch_size <= X_train.shape[0]:\n",
    "                X_batch = X_train[counter:counter + batch_size]\n",
    "                y_batch = y_train[counter:counter + batch_size]\n",
    "            else:\n",
    "                X_batch = X_train[counter:]\n",
    "                y_batch = y_train[counter:]\n",
    "            counter += batch_size\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={\n",
    "                    X: X_batch.reshape([-1, img_size, img_size, 1]),\n",
    "                    y: y_batch,\n",
    "                    mask_with_labels: True\n",
    "                }\n",
    "            )\n",
    "            print('\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}'.format(\n",
    "                iteration, n_iterations_per_epoch,\n",
    "                iteration * 100 / n_iterations_per_epoch,\n",
    "                loss_train\n",
    "            ), end='')\n",
    "        \n",
    "        # After the end of each epoch, measure validation loss and accuracy\n",
    "#         loss_vals = []\n",
    "#         acc_vals = []\n",
    "#         for iteration in range(1, n_iterations_validation + 1):\n",
    "#             X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
    "#             loss_val, acc_val = sess.run(\n",
    "#                 [loss, accuracy],\n",
    "#                 feed_dict={\n",
    "#                     X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "#                     y: y_batch,\n",
    "#                     mask_with_labels: True\n",
    "#                 }\n",
    "#             )\n",
    "#             loss_vals.append(loss_val)\n",
    "#             acc_vals.append(acc_val)\n",
    "#             print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "#                 iteration, n_iterations_validation,\n",
    "#                 iteration * 100 / n_iterations_validation\n",
    "#             ), end=' ' * 10)\n",
    "#         loss_val = np.mean(loss_vals)\n",
    "#         acc_val = np.mean(acc_vals)\n",
    "#         print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "#             epoch + 1, acc_val * 100, loss_val, \" (improved)\" if loss_val < best_loss_val else \"\"\n",
    "#         ))\n",
    "        \n",
    "#         # Save the model if it has improved\n",
    "#         if loss_val < best_loss_val:\n",
    "#             save_path = saver.save(sess, checkpoint_path)\n",
    "#             best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Caused by op 'mul', defined at:\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error, name='L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is finished. Now we will evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations_test = mnist.test.num_examples // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "        loss_test, acc_test = sess.run(\n",
    "            [loss, accuracy],\n",
    "            feed_dict={\n",
    "                X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                y: y_batch\n",
    "            }\n",
    "        )\n",
    "        loss_tests.append(loss_test)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "            iteration, n_iterations_test,\n",
    "            iteration * 100 / n_iterations_test\n",
    "        ), end=' ' * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(acc_test * 100, loss_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions, we first fix a few images from the test set, then start a session, restore the trained model, evaluate `caps2_output` to get the capsule network's output vectors, `decoder_output` to get the reconstructions, and `y_pred` to get the class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "sample_images = mnist.test.images[:n_samples].reshape([-1, 28, 28, 1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
    "        [caps2_output, decoder_output, y_pred],\n",
    "        feed_dict={\n",
    "            X: sample_images,\n",
    "            y: np.array([], dtype=np.int64)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** we feed `y` with an empty array, but Tensorflow will not use it. Check the masking section for explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images and their labels\n",
    "sample_images = sample_images.reshape(-1, 28, 28)\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(mnist.test.labels[index]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the corresponding reconstructions and predictions\n",
    "reconstructions = decoder_output_value.reshape([-1, 28, 28])\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
    "    plt.imshow(reconstructions[index], cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
