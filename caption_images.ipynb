{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import argparse\n",
    "import cv2\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from utils import print_progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    print('Creating word to vec map...')\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    print('Done!')\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word to vec map...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('{}/glove.6B.50d.txt'.format('dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_caption_vector(caption, word_to_index):\n",
    "    id_vector = []\n",
    "    words = nltk.word_tokenize(caption.lower())\n",
    "    for word in words:\n",
    "        try:\n",
    "            id_vector.append(word_to_index[word])\n",
    "        except KeyError:\n",
    "            id_vector.append(word_to_index['unk'])\n",
    "    return id_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_image_to_caption(coco, word_to_index):\n",
    "    \"\"\"\n",
    "    key: image id\n",
    "    value: a caption of the image\n",
    "    \"\"\"\n",
    "    image_to_caption = {}\n",
    "    max_len = 0\n",
    "    for img_id in coco.getImgIds():\n",
    "        annotation_id = coco.getAnnIds(img_id)[random.randint(0, 4)]  # Take any one out of 5 captions\n",
    "        caption = coco.loadAnns(annotation_id)[0]['caption']\n",
    "        image_to_caption[img_id] = create_caption_vector(caption.lower(), word_to_index)\n",
    "    max_len = len(max(image_to_caption.values(), key=len))\n",
    "    return image_to_caption, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(coco, word_to_index, image_path, img_size, dataset_size):\n",
    "    x, y = [], []\n",
    "    \n",
    "    # Load image to caption map\n",
    "    image_to_caption, max_len = map_image_to_caption(coco, word_to_index)\n",
    "\n",
    "    # Initial call to print 0% progress\n",
    "    print_progress_bar_counter = 0\n",
    "    print_progress_bar(print_progress_bar_counter, dataset_size, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "    image_to_caption_sampled = random.sample(image_to_caption.items(), dataset_size)  # shuffle items to reduce homogeneity\n",
    "    for img_id, caption_vector in image_to_caption_sampled:\n",
    "        # load image array\n",
    "        img = coco.loadImgs([img_id])[0]\n",
    "        img_array = cv2.imread('%s/%s' % (image_path, img['file_name']), cv2.IMREAD_GRAYSCALE)\n",
    "        new_img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "\n",
    "        # store data in input and output vector\n",
    "        x.append(new_img_array)\n",
    "        y.append(caption_vector + [0] * (max_len - len(caption_vector)))\n",
    "\n",
    "        # Update Progress Bar\n",
    "        print_progress_bar_counter += 1\n",
    "        print_progress_bar(print_progress_bar_counter, dataset_size, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "    \n",
    "    # convert to numpy array\n",
    "    x = np.expand_dims(np.array(x, dtype=np.float32), axis=-1).astype('float32') / 255.\n",
    "    y = np.array(y, dtype=np.int64)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory where the data is stored\n",
    "data_dir = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize coco api\n",
    "ann_file_train = '{}/annotations/captions_train2017.json'.format(data_dir)\n",
    "ann_file_val = '{}/annotations/captions_val2017.json'.format(data_dir)\n",
    "\n",
    "coco_train = COCO(ann_file_train)\n",
    "coco_val = COCO(ann_file_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('{}/glove.6B.50d.txt'.format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "x_train: (5000, 250, 250, 1)\n",
      "y_train: (5000, 55)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "x_train, y_train = create_dataset(coco_train, word_to_index, data_dir + '/train2017', 250, 5000)\n",
    "print('\\nx_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "x_val: (1500, 250, 250, 1)\n",
      "y_val: (1500, 36)\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "x_val, y_val = create_dataset(coco_val, word_to_index, data_dir + '/val2017', 250, 1500)\n",
    "print('\\nx_val:', x_val.shape)\n",
    "print('y_val:', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras import layers, models, optimizers\n",
    "from keras import callbacks\n",
    "from PIL import Image\n",
    "\n",
    "from utils import combine_images\n",
    "from capsule_layers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "n_class = 12\n",
    "routings = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1-3: Just some conventional Conv2D layers\n",
    "conv1 = layers.Conv2D(filters=96, kernel_size=13, strides=4, padding='valid', activation='relu', name='conv1')(x)\n",
    "conv2 = layers.Conv2D(filters=96, kernel_size=5, strides=2, padding='valid', activation='relu', name='conv2')(conv1)\n",
    "conv3 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv3')(conv2)\n",
    "conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 4: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "primary_caps = PrimaryCap(conv3, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "primary_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 5: Capsule layer. Routing algorithm works here.\n",
    "caption_caps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='caption_caps')(primary_caps)\n",
    "caption_caps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
