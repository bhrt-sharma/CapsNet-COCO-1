{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (10000, 250, 250, 1)\n",
      "y_train: (10000, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "h5f = h5py.File('dataset/training_data.h5', 'r')\n",
    "x_train = h5f['x_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "h5f.close()\n",
    "\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val: (2500, 250, 250, 1)\n",
      "y_val: (2500, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "# validation data\n",
    "h5f = h5py.File('dataset/validation_data.h5', 'r')\n",
    "x_val = h5f['x_val'][:]\n",
    "y_val = h5f['y_val'][:]\n",
    "h5f.close()\n",
    "\n",
    "print('x_val:', x_val.shape)\n",
    "print('y_val:', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load vocabulary and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    print('Creating word to vec map...')\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float32)\n",
    "    print('Done!')\n",
    "    return word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word to vec map...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "word_to_vec_map = read_glove_vecs('{}/glove.6B.50d.txt'.format('dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "with open('dataset/vocabulary.pickle', 'rb') as vocab_file:\n",
    "    vocabulary_dict = pickle.load(vocab_file)\n",
    "\n",
    "vocabulary = vocabulary_dict['vocabulary']\n",
    "word_to_index = vocabulary_dict['word_to_index']\n",
    "index_to_word = vocabulary_dict['index_to_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9567"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras import layers, models, optimizers\n",
    "from keras import callbacks\n",
    "from PIL import Image\n",
    "\n",
    "from utils import combine_images\n",
    "from capsule_layers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, GRU\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "n_class = 10\n",
    "routings = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv3/Relu:0' shape=(?, 20, 20, 256) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer 1-3: Just some conventional Conv2D layers\n",
    "conv1 = layers.Conv2D(filters=96, kernel_size=13, strides=4, padding='valid', activation='relu', name='conv1')(x)\n",
    "conv2 = layers.Conv2D(filters=96, kernel_size=5, strides=2, padding='valid', activation='relu', name='conv2')(conv1)\n",
    "conv3 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv3')(conv2)\n",
    "conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caption_caps/mul_2:0' shape=(?, 10, 16) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer 4: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "primary_caps = PrimaryCap(conv3, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "# Layer 5: Capsule layer. Routing algorithm works here.\n",
    "caption_caps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='caption_caps')(primary_caps)\n",
    "caption_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'capsnet/Sqrt:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_caps = Length(name='capsnet')(caption_caps)\n",
    "out_caps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define caption model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal state size of 3 GRU layers in the RNN\n",
    "state_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the interger tokens converted by the embedding layer\n",
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_transfer_map = Dense(state_size, activation='tanh', name='decoder_transfer_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = layers.Input(shape=(y_train.shape[-1], ), name='decoder_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_embedding = Embedding(input_dim=10000, output_dim=embedding_size, name='decoder_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_gru1 = GRU(state_size, name='decoder_gru1',\n",
    "                   return_sequences=True)\n",
    "decoder_gru2 = GRU(state_size, name='decoder_gru2',\n",
    "                   return_sequences=True)\n",
    "decoder_gru3 = GRU(state_size, name='decoder_gru3',\n",
    "                   return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(10000,\n",
    "                      activation='softmax',\n",
    "                      name='decoder_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect and Create the Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_transfer_map/Tanh:0' shape=(?, 512) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_initial_state = decoder_transfer_map(out_caps)\n",
    "rnn_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_embedding/embedding_lookup/Identity:0' shape=(?, 16, 100) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the decoder-network with its input-layer.\n",
    "net = decoder_input\n",
    "\n",
    "# Connect the embedding-layer.\n",
    "net = decoder_embedding(net)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_gru3/transpose_1:0' shape=(?, ?, 512) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect all the GRU layers.\n",
    "net = decoder_gru1(net, initial_state=rnn_initial_state)\n",
    "net = decoder_gru2(net, initial_state=rnn_initial_state)\n",
    "net = decoder_gru3(net, initial_state=rnn_initial_state)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_output/truediv:0' shape=(?, 16, 10000) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the final dense layer that converts to\n",
    "# one-hot encoded arrays.\n",
    "decoder_output = decoder_dense(net)\n",
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(inputs=[x, decoder_input],\n",
    "                      outputs=[decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 60, 60, 96)   16320       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 28, 28, 96)   230496      conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 20, 20, 256)  1990912     conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 6, 6, 256)    5308672     conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1152, 8)      0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1152, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "caption_caps (CapsuleLayer)     (None, 10, 16)       1474560     primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 10)           0           caption_caps[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, 16, 100)      1000000     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_transfer_map (Dense)    (None, 512)          5632        capsnet[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru1 (GRU)              (None, 16, 512)      941568      decoder_embedding[0][0]          \n",
      "                                                                 decoder_transfer_map[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru2 (GRU)              (None, 16, 512)      1574400     decoder_gru1[0][0]               \n",
      "                                                                 decoder_transfer_map[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru3 (GRU)              (None, 16, 512)      1574400     decoder_gru2[0][0]               \n",
      "                                                                 decoder_transfer_map[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 16, 10000)    5130000     decoder_gru3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,246,960\n",
      "Trainable params: 19,246,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "decoder_model.compile()\n",
    "decoder_model.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
